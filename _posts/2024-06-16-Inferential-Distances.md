---
layout: "post"
title: "Inferential Distances"
date: "2024-06-16 10:00:00 +0100"
published: true
---

_Homo sapiens_'s environment of evolutionary adaptedness (a.k.a. EEA or “ancestral environment”) consisted of hunter-gatherer bands of at most [200 people](https://en.wikipedia.org/wiki/Dunbar%27s_number), with no writing. All inherited knowledge was passed down by speech and memory.

**In a world like that, all background knowledge is universal knowledge. All information not strictly private is public, period.**

In the ancestral environment, you were **unlikely** to end up more than _one inferential step_ away from anyone else.

> “When you discover a new oasis, you don’t have to explain to your fellow tribe members what an oasis is, or why it’s a good idea to drink water, or how to walk.”  
> **Only you know where the oasis lies; this is private knowledge.**

But everyone shares the background needed to understand your description of the oasis—the concepts required to think about water. In such an environment, **you almost _never_ have to explain your concepts.** At most, you have to explain _one_ new concept, not two or more simultaneously.

In the ancestral environment there were no abstract disciplines with vast bodies of carefully gathered evidence generalized into elegant theories transmitted by written books—whose conclusions are _a hundred inferential steps removed_ from universally shared background premises.

In that world, anyone who says something with no **obvious support is a liar or an idiot.** You’re not likely to think, “Hey, maybe this person has well-supported background knowledge that no one in my band has even heard of,” **because it was a reliable invariant of the ancestral environment that this didn’t happen.**

Conversely, if you say something blatantly obvious and the other person doesn’t see it, _they’re_ the idiot—or they’re being deliberately obstinate to annoy you.

And to top it off, if someone says something with no obvious support and _expects_ you to believe it—acting indignant when you don’t—then they must be _crazy_.

Combined with the illusion of transparency and **self-anchoring** (the tendency to model other minds as though they were slightly modified versions of oneself), this helps explain a _lot_ about the legendary difficulty most scientists have in communicating with a lay audience—or even with scientists from other disciplines. When I observe failures of explanation, I usually see the explainer taking _one_ step back when they actually need to take two or more steps back. Likewise, listeners sometimes assume that everything should be visible in one step, even though explaining a concept may require two or more steps. Both sides seem to expect very short inferential distances from universal knowledge to any new knowledge.

For example, a biologist speaking to a physicist might justify evolution by saying it is the simplest explanation. But not everyone on Earth has been inculcated with that legendary history of science—from Newton to Einstein—which imbues the phrase “simplest explanation” with its awesome import: a Word of _Power_, spoken at the birth of theories and carved on their tombstones. To someone else, “But it’s the simplest explanation!” may sound like an interesting but hardly knockdown argument; it doesn’t feel like a powerful tool for comprehending office politics or fixing a broken car. Clearly, the biologist is infatuated with their own ideas—too arrogant to be open to alternative explanations that sound just as plausible. (If it sounds plausible to me, it should sound plausible to any sane member of my band.)

From the biologist’s perspective, they might understand how evolution could sound a little odd at first—but when someone rejects evolution even after the biologist explains that it’s the simplest explanation, it becomes clear (to the biologist) that nonscientists are just idiots and that there’s no point in talking to them.

A clear argument has to lay out an inferential _pathway_, starting from what the audience _already knows or accepts_. If you don’t recurse far enough, you’re just talking to yourself. If at any point you make a statement without obvious justification in arguments you’ve previously supported, the audience will simply think you’re crazy.

This failure also occurs when you allow yourself to be seen _visibly_ attaching greater weight to an argument than is justified in the eyes of the audience _at that time_. For instance, talking as if you think “simpler explanation” is a knockdown argument for evolution (which, in principle, it is) rather than merely a somewhat interesting idea (which it may sound like to someone who wasn’t raised to revere Occam’s Razor).

And you’d better not drop any hints that _you_ think you’re working a dozen inferential steps away from what the audience knows, or that _you_ possess special background knowledge not available to them. The audience doesn’t know anything about an evolutionary-psychological argument for a cognitive bias to underestimate inferential distances that lead to traffic jams in communication—they’ll just think you’re condescending.

And if you think you can explain the concept of “systematically underestimated inferential distances” briefly—in just a few words—well, I’ve got some sad news for you.

---

## REMARKS

### 1. The Burden of Explanation

The explanation drawn from the ancestral environment seems plausible. **However, there is also a rational argument for refusing to accept a claim unless all the steps from one's own knowledge to the claim are clearly laid out.** While there are genuine truth seekers who have found truth and who, ideally, should be believed, a blanket policy of accepting individuals at their word can render people vulnerable to misinformation—because they are not equipped to distinguish between falsehoods and true statements that are many inferential steps removed from their own knowledge.

**Despite this, people do not universally reject claims that are far removed from their own experience.** Scientists, for instance, have successfully communicated complex ideas to the public. Yet, misinformation also regularly gains traction; society has always had niches for individuals claiming esoteric knowledge.

### 2. Vulnerability of the Young

**Young individuals appear especially vulnerable to accepting whatever they are told.** This includes not only mythical figures like Santa Claus but also any information provided by their schools. Educational institutions for the young are particularly effective tools for indoctrination. **In contrast, older individuals tend to be more resistant to new claims, which can be both beneficial and detrimental.**

An evolutionary explanation is plausible here. Children need to learn as much as possible, as quickly as possible, for survival. Adults play a crucial role as their teachers, and in doing so, it is advantageous for adults to be less receptive to new claims, ensuring that their knowledge remains a reliable archive of past lessons. Conversely, it benefits the young to accept information readily without spending excessive time questioning it.

### 3. The Simplicity Paradox

When arguing with a young Earth creationist, they might fully understand the scientific explanation yet simply disagree, asserting that "God did it" is a simpler explanation. Indeed, if one presupposes the existence of an intelligent being with infinite power, that might be seen as simpler.

Most individuals who do not believe in an omnipotent designer tend to accept evolution relatively quickly, suggesting that the cognitive issue may not lie in the acceptance of evolutionary theory itself.  
There are other complex, deep-rooted belief systems—such as opposition to free trade—but the rejection of evolution in favor of creationism is particularly intricate and entrenched.

Introducing God into the explanation actually increases the complexity of the theory in terms of the amount of information stored. The time required to explain a theory does not necessarily correlate with its simplicity. "God did it" is significantly more complex than "The random process of natural selection ensures that organisms with beneficial mutations are more likely to survive and pass those genes on to the next generation."

If examined closely, these two arguments do not necessarily contradict each other. While "God did it" might be perceived as simpler compared to "Amino acids magically combined through processes we don't fully understand, creating life essentially ex nihilo," this does not mean that either explanation is objectively simple.
